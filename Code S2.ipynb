{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to create a forecasting dataset with additional features\n",
        "def create_forecasting_dataset_with_additional_features(data, start_date, end_date, history_window_days, forecast_window_days):\n",
        "    new_data = []\n",
        "\n",
        "    # Process only the data within the specified date range\n",
        "    valid_data = data[(data['Time'] >= start_date) & (data['Time'] <= end_date)]\n",
        "\n",
        "    for current_day in valid_data['Time']:\n",
        "        # History window: Previous 100 days\n",
        "        history_start = current_day - pd.Timedelta(days=history_window_days)\n",
        "        history_window = data[(data['Time'] >= history_start) & (data['Time'] < current_day)]\n",
        "\n",
        "        # Forecast window: Next 100 days\n",
        "        forecast_end = current_day + pd.Timedelta(days=forecast_window_days)\n",
        "        forecast_window = data[(data['Time'] > current_day) & (data['Time'] <= forecast_end)]\n",
        "\n",
        "        # If both history window and forecast window contain enough data\n",
        "        if not history_window.empty and not forecast_window.empty:\n",
        "            # History window features\n",
        "            max_magnitude = history_window['Magnitude'].max()\n",
        "            mean_magnitude = history_window['Magnitude'].mean()\n",
        "            std_magnitude = history_window['Magnitude'].std()\n",
        "            mean_depth = history_window['Depth'].mean()\n",
        "            earthquake_frequency = len(history_window) / history_window_days\n",
        "            earthquake_numbers = len(history_window)\n",
        "            avg_energy = history_window['Energy'].mean() if 'Energy' in history_window.columns else np.nan\n",
        "            std_energy = history_window['Energy'].std() if 'Energy' in history_window.columns else np.nan\n",
        "            mean_b_value = history_window['b_value'].mean()\n",
        "            std_b_value = history_window['b_value'].std()\n",
        "            b_value_ratio = std_b_value / mean_b_value if mean_b_value != 0 else np.nan\n",
        "            total_energy = history_window['Energy'].sum() if 'Energy' in history_window.columns else np.nan\n",
        "            energy_density = total_energy / earthquake_numbers if earthquake_numbers > 0 else np.nan\n",
        "\n",
        "            # Elapsed Time: Time since the last earthquake\n",
        "            elapsed_time = (current_day - history_window['Time'].max()).total_seconds() / 3600 if not history_window.empty else np.nan\n",
        "\n",
        "            # Future window target variable\n",
        "            future_max_magnitude = forecast_window['Magnitude'].max()\n",
        "\n",
        "            # Append the new data row\n",
        "            new_data.append([\n",
        "                current_day, max_magnitude, mean_magnitude, std_magnitude, mean_depth,\n",
        "                earthquake_frequency, earthquake_numbers, avg_energy, std_energy, mean_b_value,\n",
        "                std_b_value, b_value_ratio, total_energy, energy_density,\n",
        "                elapsed_time, future_max_magnitude\n",
        "            ])\n",
        "\n",
        "    # Create new DataFrame\n",
        "    new_df = pd.DataFrame(\n",
        "        new_data,\n",
        "        columns=[\n",
        "            'Time', 'Max_Magnitude', 'Mean_Magnitude', 'Std_Magnitude', 'Mean_Depth',\n",
        "            'Earthquake_Frequency', 'Earthquake_Numbers', 'Mean_Energy', 'Std_Energy',\n",
        "            'Mean_b_value', 'Std_b_value', 'b_value_ratio', 'Total_Energy', 'Energy_Density',\n",
        "            'Elapsed_Time', 'Future_Max_Magnitude'\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return new_df\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Marmara1990V1.csv')\n",
        "\n",
        "# Clean extra spaces in column names\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# Check for missing 'b_value' column\n",
        "if 'b_value' not in data.columns:\n",
        "    data['b_value'] = np.nan  # Create the missing column\n",
        "\n",
        "# Convert 'Time' column to datetime format\n",
        "data['Time'] = pd.to_datetime(data['Time'])\n",
        "\n",
        "# Sort DataFrame by time\n",
        "data = data.sort_values(by='Time')\n",
        "\n",
        "# Calculate the time difference between earthquakes\n",
        "data['Time_Difference'] = data['Time'].diff().dt.total_seconds() / 3600  # Time difference in hours\n",
        "data['Time_Difference'].fillna(data['Time_Difference'].mean(), inplace=True)  # Fill the first difference\n",
        "\n",
        "# 100-day moving average and standard deviation\n",
        "data['Time_Diff_MA'] = data['Time_Difference'].rolling(window=100, min_periods=1).mean()\n",
        "data['Time_Diff_Std'] = data['Time_Difference'].rolling(window=100, min_periods=1).std()\n",
        "data['b_value_MA'] = data['b_value'].rolling(window=100, min_periods=1).mean()\n",
        "data['b_value_Std'] = data['b_value'].rolling(window=100, min_periods=1).std()\n",
        "\n",
        "# Set the start date as 100 days after the first record\n",
        "start_date = data['Time'].min() + pd.Timedelta(days=100)\n",
        "end_date = data['Time'].max() - pd.Timedelta(days=100)\n",
        "\n",
        "# History and forecast window days\n",
        "history_window_days = 100\n",
        "forecast_window_days = 100\n",
        "\n",
        "# Create the forecasting dataset\n",
        "forecasting_data = create_forecasting_dataset_with_additional_features(data, start_date, end_date, history_window_days, forecast_window_days)\n",
        "\n",
        "# Save the new dataset to CSV\n",
        "output_file = \"forecasting_dataset_with_all_features.csv\"\n",
        "forecasting_data.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"The new forecasting dataset has been saved to '{output_file}'.\")\n"
      ],
      "metadata": {
        "id": "pP0uKEXKhXIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}